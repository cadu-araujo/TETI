{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddeb03c9-e8f8-46c1-a949-0260942232db",
   "metadata": {},
   "source": [
    "## É necessário baixar bibliotecas e funções padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c645f0-c1eb-46b3-8201-6d78df6fb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402fce71-6c71-4dea-9d8f-703e0cbc9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_faixa_cores(cor):\n",
    "    faixas_hsv = {\n",
    "        \"green\": ((36, 50, 50), (85, 255, 255)),\n",
    "        \"blue\": ((90, 50, 50), (128, 255, 255)),\n",
    "        \"yellow\": ((22, 50, 50), (38, 255, 255)),\n",
    "        \"pink\": ((160, 50, 50), (170, 255, 255)),\n",
    "        \"orange\": ((11, 50, 50), (25, 255, 255))\n",
    "    }\n",
    "    return faixas_hsv.get(cor.lower(), \"Cor inválida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ed4fad-170a-4330-b965-bac0d5a2a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = path + 'video1.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489db27f-8c70-4c59-b9eb-2be8fb042132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizou  a geração dos frames.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "cont = 1\n",
    "if cap.isOpened():\n",
    "    rval, frame = cap.read()\n",
    "else:\n",
    "    rval = False\n",
    "while rval:\n",
    "    rval, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        #cv2.imwrite(path2 + '/quadros/' + str(cont) + '.jpg', frame)\n",
    "        cont+=1\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Finalizou  a geração dos frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e8689b-ec38-40e0-8679-91c84f5fe094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_im6(im1, tit1, im2, tit2, im3, tit3, im4, tit4,im5, tit5,im6, tit6,tam):\n",
    "    figure(figsize = tam)\n",
    "    plt.subplot(1,6,1), plt.imshow(im1), plt.title(tit1)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,6,2), plt.imshow(im2), plt.title(tit2)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,6,3), plt.imshow(im3), plt.title(tit3)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,6,4), plt.imshow(im4), plt.title(tit4)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,6,5), plt.imshow(im5), plt.title(tit5)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,6,6), plt.imshow(im6), plt.title(tit6)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40632631-f829-4790-ac54-ecfcf8a33963",
   "metadata": {},
   "source": [
    "## caminho para arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d42025d-69bc-4c5a-aeb8-22827e9eda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/user/visao_am/imagens_visao_am/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2e34e-2864-4532-af49-e49efafa5546",
   "metadata": {},
   "source": [
    "### imagem e vídeos trabalhados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5216d63-482f-4654-8d6d-bca0868753b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_p = path + 'video_tra.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232cecc3-30a4-4625-905a-3512384965a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_o = array(Image.open(path + \"im_tra.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6acda6-d653-4535-b624-f6ed4a78f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow (im_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e39ad-9dfb-4097-8e9d-f97c9d9e2cc2",
   "metadata": {},
   "source": [
    "## criei função onde é escolhida a cor e plotada a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abddc62a-95bb-4d5e-902d-0e33174a63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolhe_cor(cor, img):\n",
    "\n",
    "    im_pa = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    if (cor==\"a\"):\n",
    "        limiar_claro = np.array([22, 50, 50])\n",
    "        limiar_escuro = np.array([38, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    elif (cor==\"v\"):\n",
    "        limiar_claro = np.array([36, 50, 50])\n",
    "        limiar_escuro = np.array([85, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    elif (cor==\"p\"):\n",
    "        limiar_claro = np.array([160, 50, 50])\n",
    "        limiar_escuro = np.array([170, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    elif (cor==\"l\"):\n",
    "        limiar_claro = np.array([11, 50, 50])\n",
    "        limiar_escuro = np.array([25, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    elif (cor==\"b\"):\n",
    "        limiar_claro = np.array([90, 50, 50])\n",
    "        limiar_escuro = np.array([128, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    elif (cor==\"r\"):\n",
    "        limiar_claro = np.array([0, 50, 50])\n",
    "        limiar_escuro = np.array([10, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)\n",
    "    else:\n",
    "        limiar_claro = np.array([90, 50, 50])\n",
    "        limiar_escuro = np.array([128, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return imshow(saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d643f-720d-44a2-a134-cab42202a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_arara = cv2.imread(path +'arara_azul.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8dcd6-6032-42de-bfeb-ec03857089ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"r\", im_arara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f6b4f-e1ef-49a6-9cb3-9308edb4053b",
   "metadata": {},
   "source": [
    "## configurada já no azul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5903662-f6fa-4853-b70b-0743dcb3d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_p = cv2.imread(path +'im_tra.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6df14a-7cf4-40d8-ba13-1d9ab804d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39bede-97a1-4de1-8a10-33978ea66cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"r\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34226ce6-c005-47e5-af25-86e4324904e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"v\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98487432-a250-4914-8cf3-54a9e63cc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"l\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10f13f-5746-4a1c-b167-97e4c24f0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"a\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4edad8-8ddd-4d3b-831b-5dae0fb24350",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolhe_cor(\"\", im_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c2c7a-11c3-4830-ad3a-20cf9b0144f9",
   "metadata": {},
   "source": [
    "## outra função que só retorna a img trabalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79bebb24-c0bf-4919-b617-5493e617cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolhe_cor_ (cor, img):\n",
    "\n",
    "    im_pa = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    if (cor==\"a\"):\n",
    "        limiar_claro = np.array([22, 50, 50])\n",
    "        limiar_escuro = np.array([38, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"v\"):\n",
    "        limiar_claro = np.array([36, 50, 50])\n",
    "        limiar_escuro = np.array([85, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"p\"):\n",
    "        limiar_claro = np.array([160, 50, 50])\n",
    "        limiar_escuro = np.array([170, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"l\"):\n",
    "        limiar_claro = np.array([11, 50, 50])\n",
    "        limiar_escuro = np.array([25, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"b\"):\n",
    "        limiar_claro = np.array([90, 50, 50])\n",
    "        limiar_escuro = np.array([128, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"r\"):\n",
    "        limiar_claro = np.array([170, 50, 50])\n",
    "        limiar_escuro = np.array([180, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"m\"):\n",
    "        limiar_claro = np.array([145, 50, 50])\n",
    "        limiar_escuro = np.array([160, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"d\"):\n",
    "        limiar_claro = np.array([120, 50, 50])\n",
    "        limiar_escuro = np.array([140, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    elif (cor==\"e\"):\n",
    "        limiar_claro = np.array([0, 0, 0])\n",
    "        limiar_escuro = np.array([180, 250, 50])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida\n",
    "    else:\n",
    "        limiar_claro = np.array([90, 50, 50])\n",
    "        limiar_escuro = np.array([128, 255, 255])\n",
    "        mask = cv2.inRange(im_pa, limiar_claro, limiar_escuro)\n",
    "        saida = cv2.bitwise_and(im_pa, im_pa, mask = mask)\n",
    "        return saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8046242d-f07f-48fa-83f3-c10304b94d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "video3 = path + 'mont_russa.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023207b-4e47-47ea-8282-7c78a698cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rosa = escolhe_cor_(\"r\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e3efd-a3bd-47d9-9b8b-8ee31afeb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_azul = escolhe_cor_(\"\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d261c1f-efbc-4557-8434-03b1288cfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_verde = escolhe_cor_(\"v\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eafbff-e9fb-431b-a739-33c4fb1e59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_amarelo = escolhe_cor_(\"a\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bd9c2-a9ae-4f8c-bbb1-54348ea192d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_laranja = escolhe_cor_(\"l\", im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b03626-254e-4528-b4e6-49c91965680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_im6 (im_o, \"Original\",im_rosa, \"Rosa\",im_azul, \"Azul\",im_verde, \"Verde\",im_amarelo, \"Amarelo\",im_laranja, \"Laranja\",(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d3925-2817-472b-8401-66bf7334d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35a3da20-c7e9-4cd9-a6a4-8091891ca823",
   "metadata": {},
   "source": [
    "## aqui eu faço o uso desta função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9156f9ee-97f5-448f-b405-b8c2074d3400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizou  a geração dos frames.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "cont = 1\n",
    "op = \"\"\n",
    "if cap.isOpened():\n",
    "    rval, frame = cap.read()\n",
    "else:\n",
    "    rval = False\n",
    "while rval:\n",
    "    rval, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        saida = escolhe_cor_ (op, frame)\n",
    "        cv2.imshow('Frame', saida)\n",
    "        cont+=1\n",
    "        key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('b'):\n",
    "        op = \"b\"\n",
    "    if key == ord('a'):\n",
    "        op = \"a\"\n",
    "    if key == ord('r'):\n",
    "        op = \"r\"\n",
    "    if key == ord('l'):\n",
    "        op = \"l\"\n",
    "    if key == ord('v'):\n",
    "        op = \"v\"\n",
    "    if key == ord('d'):\n",
    "        op = \"d\"\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Finalizou  a geração dos frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fbf5a-0f7a-4512-bad0-a286cf081aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "limiar_claro = np.array([22, 50, 50])\n",
    "limiar_escuro = np.array([38, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eb6270f-576a-4582-bcd6-ecaf0f713158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizou  a geração dos frames.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video3)\n",
    "cont = 1\n",
    "op = \"\"\n",
    "if cap.isOpened():\n",
    "    rval, frame = cap.read()\n",
    "else:\n",
    "    rval = False\n",
    "while rval:\n",
    "    rval, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        saida = escolhe_cor_ (op, frame)\n",
    "        cv2.imshow('Frame', saida)\n",
    "        cont+=1\n",
    "        key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('b'):\n",
    "        op = \"b\"\n",
    "    elif key == ord('a'):\n",
    "        op = \"a\"\n",
    "    elif key == ord('r'):\n",
    "        op = \"r\"\n",
    "    elif key == ord('l'):\n",
    "        op = \"l\"\n",
    "    elif key == ord('v'):\n",
    "        op = \"v\"\n",
    "    elif key == ord('p'):\n",
    "        op = \"p\"\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Finalizou  a geração dos frames.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e464d-c704-400d-9973-468f5ef60768",
   "metadata": {},
   "source": [
    "## criei uma função para executar tudo de uma vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f029cde8-9859-4425-a144-b6ee738656fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_cor (video, cor):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cont = 1\n",
    "    op = cor\n",
    "    if cap.isOpened():\n",
    "        rval, frame = cap.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    while rval:\n",
    "        rval, frame = cap.read()\n",
    "        if frame is not None:\n",
    "            saida = escolhe_cor_ (op, frame)\n",
    "            cv2.imshow('Cores', saida)\n",
    "            cont+=1\n",
    "            key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('b'):\n",
    "            op = \"b\"\n",
    "        if key == ord('a'):\n",
    "            op = \"a\"\n",
    "        if key == ord('p'):\n",
    "            op = \"p\"\n",
    "        if key == ord('l'):\n",
    "            op = \"l\"\n",
    "        if key == ord('v'):\n",
    "            op = \"v\"\n",
    "        if key == ord('r'):\n",
    "            op = \"r\"\n",
    "        if key == ord('m'):\n",
    "            op = \"m\"\n",
    "        if key == ord('d'):\n",
    "            op = \"d\"\n",
    "        if key == ord('e'):\n",
    "            op = \"e\"\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Finalizou  a geração dos frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47a865b6-d148-4c84-8444-0730ff1b7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizou  a geração dos frames.\n"
     ]
    }
   ],
   "source": [
    "video_cor(0, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07c6e6ab-c8f7-4809-a2fc-33c29d6c090f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m video_cor(\u001b[43mvideo_p\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_p' is not defined"
     ]
    }
   ],
   "source": [
    "video_cor(video_p, \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2da2e8-9f32-4386-b93e-a82593d0a663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488e561-b7fc-445f-abf5-a3d0d00c925e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d6fb6-a35f-4b1b-abd6-7735e8422af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1c0ba-3aa1-4665-b893-f9a53614f6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece9b03-e948-4ae1-af71-5bbbedc1f4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
